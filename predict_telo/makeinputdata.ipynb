{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ca3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code prepares input data for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e7f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools    \n",
    "import random    \n",
    "import math\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from Bio.Seq import Seq #biopython\n",
    "import subprocess\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "######################### Produce data from centromere and \"chromatin proper\"\n",
    "#########################\n",
    "\n",
    "windowsize=50\n",
    "\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "num_random_read_in_seq = 50000\n",
    "\n",
    "def create_data_for_read(oneseq, onestart):\n",
    "    oneseq = oneseq.upper()\n",
    "    #print(use_i)\n",
    "\n",
    "    onepos = [0]*onestart + list(range(0,len(oneseq)-onestart))\n",
    "\n",
    "    def getavglist(lst):\n",
    "        return sum(lst)/len(lst)\n",
    "\n",
    "\n",
    "    focuslen = len(oneseq)\n",
    "\n",
    "    list_randomstart = [random.randint(0,focuslen-windowsize) for x in range(0,num_random_read_in_seq)]\n",
    "    list_randomseq = [oneseq[randomstart:(randomstart+windowsize)] for randomstart in list_randomstart]\n",
    "    list_randompos = [getavglist(onepos[randomstart:(randomstart+windowsize)]) for randomstart in list_randomstart]\n",
    "\n",
    "    mer8 = pd.DataFrame({\n",
    "        \"seq\":list_randomseq,\n",
    "        \"score\":list_randompos\n",
    "    })\n",
    "    return(mer8)\n",
    "\n",
    "def get_reads_from_record(record):\n",
    "    print(record.id)\n",
    "    \n",
    "    if len(record.seq)<100000:\n",
    "        return(pd.DataFrame({\n",
    "            \"start\":[],\n",
    "            \"seq\":[]\n",
    "        }))\n",
    "    else:\n",
    "        return(create_data_for_read(str(record.seq), 0))\n",
    "\n",
    "all_nc = pd.concat([\n",
    "    get_reads_from_record(record) for record\n",
    "    in SeqIO.parse(\"/corgi/otherdataset/t2t/other/simplified_noncentromere.fa\", \"fasta\")])\n",
    "\n",
    "all_c = pd.concat([\n",
    "    get_reads_from_record(record) for record\n",
    "    in SeqIO.parse(\"/corgi/otherdataset/t2t/other/simplified_centromere.fa\", \"fasta\")])\n",
    "\n",
    "all_nc[\"score\"] = 0 \n",
    "all_c[\"score\"] = 1  \n",
    "print(\"done\")\n",
    "\n",
    "all_c.to_pickle(\"/husky/otherdataset/karimian2024/t2t_centro_50.pickle\")\n",
    "all_nc.to_pickle(\"/husky/otherdataset/karimian2024/t2t_noncentro_50.pickle\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8dffd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/husky/otherdataset/karimian2024/more/3048693\n",
      "/husky/otherdataset/karimian2024/more/3048691\n",
      "/husky/otherdataset/karimian2024/more/3048695\n",
      "/husky/otherdataset/karimian2024/more/3048694\n",
      "/husky/otherdataset/karimian2024/more/3048696\n",
      "/husky/otherdataset/karimian2024/more/3048698\n",
      "/husky/otherdataset/karimian2024/more/3048697\n",
      "/husky/otherdataset/karimian2024/more/3048699\n",
      "/husky/otherdataset/karimian2024/more/3048700\n",
      "/husky/otherdataset/karimian2024/more/3048701\n",
      "/husky/otherdataset/karimian2024/more/3048703\n",
      "/husky/otherdataset/karimian2024/more/3048702\n",
      "/husky/otherdataset/karimian2024/more/3048709\n",
      "/husky/otherdataset/karimian2024/more/3048704\n",
      "/husky/otherdataset/karimian2024/more/3048705\n",
      "/husky/otherdataset/karimian2024/more/3048708\n",
      "/husky/otherdataset/karimian2024/more/3048706\n",
      "/husky/otherdataset/karimian2024/more/3048707\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "######################### Produce data from long read of telomeres\n",
    "#########################\n",
    "\n",
    "\n",
    "def findall(p, s):\n",
    "    '''Yields all the positions of\n",
    "    the pattern p in the string s.'''\n",
    "    i = s.find(p)\n",
    "    while i != -1:\n",
    "        yield i\n",
    "        i = s.find(p, i+1)\n",
    "\n",
    "\n",
    "#########################\n",
    "# One issue here is that we could match a bit more; something for a regexp?\n",
    "def find_telomere_length(line):\n",
    "    i = 0\n",
    "    while True:\n",
    "        ne = line.find(\"TAACCC\",i)\n",
    "        if ne == -1:\n",
    "            break\n",
    "        if ne-i > 18: #seems forgiving enough\n",
    "            break\n",
    "        i = ne+6\n",
    "    return(i)\n",
    "\n",
    "\n",
    "def read_longread_file(fname):\n",
    "    mycmd=subprocess.getoutput('zcat '+fname+' | grep CCCTCCGATA')\n",
    "\n",
    "    def remove_telotag(line):\n",
    "        return line[0:line.rfind('CCCTCCGATA')]\n",
    "\n",
    "    lines=mycmd.splitlines()\n",
    "    lines = [remove_telotag(s) for s in lines]\n",
    "\n",
    "    #Reverse complement all lines such that they begin with the telomere\n",
    "    lines = [str(Seq(s).reverse_complement()) for s in lines]\n",
    "\n",
    "    lens = [find_telomere_length(s) for s in lines]\n",
    "    df = pd.DataFrame({\n",
    "        \"start\":lens,\n",
    "        \"seq\":lines\n",
    "    })\n",
    "    df = df[df[\"start\"]>50]\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "### random number on 0... maxval \n",
    "def randint_logscale(maxval):\n",
    "    r=random.uniform(0,math.log(1+maxval))\n",
    "    return(int(math.exp(r)-1))    \n",
    "\n",
    "\n",
    "def create_data_for_read(seqdata, use_i):\n",
    "    #print(use_i)\n",
    "\n",
    "    oneseq=seqdata[\"seq\"][use_i].upper()\n",
    "    onestart=seqdata[\"start\"][use_i]\n",
    "\n",
    "    onepos = [0]*onestart + list(range(0,len(oneseq)-onestart))\n",
    "\n",
    "    mer8 = pd.DataFrame({\n",
    "        \"seq\":[oneseq],\n",
    "        \"pos\":[onepos]\n",
    "    })\n",
    "    return(mer8)\n",
    "\n",
    "def create_data_for_file(fname):\n",
    "    print(fname)\n",
    "    seqdata = read_longread_file(str(fname))\n",
    "    list_for_file = [create_data_for_read(seqdata, use_i) for use_i in seqdata.index]\n",
    "    return(pd.concat(list_for_file))\n",
    "\n",
    "\n",
    "#seqdata = read_longread_file(\"/husky/otherdataset/karimian2024/more/3048691\")\n",
    "directory = \"/husky/otherdataset/karimian2024/more\"\n",
    "files = Path(directory).glob('*')\n",
    "list_mer8 = [create_data_for_file(fname) for fname in files]\n",
    "mer8 = pd.concat(list_mer8)\n",
    "\n",
    "mer8[1:10000].to_pickle(\"/husky/otherdataset/karimian2024/train_telo_xbp.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
